---
 arch/arm/kernel/process.c     |    5 	4 +	1 -	0 !
 arch/arm/kernel/vmlinux.lds.S |    2 	2 +	0 -	0 !
 arch/arm/mm/Makefile          |    2 	1 +	1 -	0 !
 arch/arm/mm/fault.c           |   96 	94 +	2 -	0 !
 arch/arm/mm/matrace.S         |   53 	53 +	0 -	0 !
 init/main.c                   |   53 	53 +	0 -	0 !
 6 files changed, 207 insertions(+), 4 deletions(-)

Index: b/arch/arm/mm/fault.c
===================================================================
--- a/arch/arm/mm/fault.c
+++ b/arch/arm/mm/fault.c
@@ -19,7 +19,6 @@
 #include <asm/pgtable.h>
 #include <asm/tlbflush.h>
 #include <asm/uaccess.h>
-
 #include "fault.h"
 
 
@@ -343,6 +342,10 @@ do_page_fault(unsigned long addr, unsign
 }
 #endif					/* CONFIG_MMU */
 
+void test_func(void)
+{
+	printk("in test func\n");
+}
 /*
  * First Level Translation Fault Handler
  *
@@ -368,7 +371,8 @@ do_translation_fault(unsigned long addr,
 	unsigned int index;
 	pgd_t *pgd, *pgd_k;
 	pmd_t *pmd, *pmd_k;
-
+	//printk("asdfasd%x\n", addr);
+	//show_pos();
 	if (addr < TASK_SIZE)
 		return do_page_fault(addr, fsr, regs);
 
@@ -391,6 +395,77 @@ do_translation_fault(unsigned long addr,
 
 	if (pmd_none(*pmd_k))
 		goto bad_area;
+	{
+
+#include <asm/pgtable.h>
+#include <asm/tlbflush.h>
+		unsigned int pc, inst ;
+		extern unsigned int trapped_pc, origin_inst;
+		unsigned long offset;
+		extern void lb2;
+		void *fnp = test_func;
+		extern unsigned int matrace_v;
+		extern pmd_t  matrace_saved_pmd;
+		if (addr >= matrace_v) { /* Have to consider all area affected */
+			printk("\n------------- do_translation_fault --------------------------------\n");
+			printk("accessed addr: %x\n", addr);
+			//__asm__("mov %0, r14"
+			//	:"=r"(pc)); /* mov pc, r14 */
+			*pmd_k = matrace_saved_pmd;
+			flush_tlb_all(); /* need to be optimized */
+			flush_pmd_entry(pmd_k);
+			v6_flush_kern_cache_all();
+			__asm__("mov %0, pc"
+				:"=r"(pc));
+			//__asm__("add lr, lr, #4");
+			//__asm__("mov pc, %0"::"r"(fnp));
+			//test_func();
+			//__asm__("lable: mov %0
+			//__asm__("lb2:");
+			//printk("pc %x\n", pc);
+			trapped_pc = regs->ARM_pc;
+			inst = *((unsigned int*)(trapped_pc + 4));
+			printk("orig inst at pc+4: %x\n", inst);
+			//*(unsigned int*)(trapped_pc + 4) = 0xdeadbeef;
+			//*(unsigned int*)(trapped_pc + 4) = inst;
+			{
+				/* make a "b matrace_magic" instruction */
+/* Found from an ARM instruction set manual */
+#define COND_SHIFT	28 /* condition shift in a ARM "B" instruction */
+#define OP_SHIFT	25 /* Operator code shift */
+#define L_SHIFT		24 /* L bit shift */
+#define ADDR_SHIFT	0  /* Address shift */
+				void matrace_magic(void);
+				unsigned int b_inst;
+				unsigned int dist;
+
+					if ((unsigned int) matrace_magic >= trapped_pc)
+					dist = (unsigned int)matrace_magic - trapped_pc - 4; /* check out why -4 is needed */
+				else
+					dist = ((unsigned int)matrace_magic - trapped_pc - 4) & (( 0x1 << 27) - 1);
+				printk("matrace_magic: %x trapped_pc: %x dist: %x \n",
+				       (unsigned int)matrace_magic, trapped_pc, dist);
+				/* folowing instruction:
+				 *   from_addr: b addr_code ;; jump to to_addr
+				 *
+				 * to_addr = from_addr + 8 + (addr_code << 2)
+				 * Thus: addr_code = (to_addr - from_addr - 8) >> 2
+				 */
+				b_inst = (0xe << COND_SHIFT) /* 0xe means always */
+					| (0x5 << OP_SHIFT) /* B and BL 's op code */
+					| (0 << L_SHIFT)    /* no link */
+					| (((dist - 8) >> 2) << ADDR_SHIFT);
+				printk("b_intst: %x\n", b_inst);
+				origin_inst = *((unsigned int *)(trapped_pc + 4)); /* save original instruction */
+				*((unsigned int *)(trapped_pc + 4)) = b_inst;
+				//v6_coherent_kern_range(trapped_pc - 128, trapped_pc + 128);
+				v6_flush_kern_cache_all();
+				printk("inst at trapped_pc + 4 after modification: %x\n",
+				       *((unsigned int *)(trapped_pc + 4)));
+				printk("---------------------------------------------\n\n");
+			}
+		}
+	}
 
 	copy_pmd(pmd, pmd_k);
 	return 0;
@@ -399,6 +474,23 @@ bad_area:
 	do_bad_area(addr, fsr, regs);
 	return 0;
 }
+
+unsigned int trapped_pc;
+unsigned int origin_inst; /* original instruction */
+
+/*
+ * void matrace_magic(void)
+ * {
+ * 	printk("we got here\n\n\n\n");
+ * 	*((unsigned int *)(trapped_pc + 4)) = origin_inst; /\* restore the original instruction *\/
+ * 	__asm__("ldmia	sp, {fp, sp }");
+ * 	__asm__("mov pc, %0"
+ * 		::"r"(trapped_pc + 4));
+ * }
+ */
+
+
+
 #else					/* CONFIG_MMU */
 static int
 do_translation_fault(unsigned long addr, unsigned int fsr,
Index: b/init/main.c
===================================================================
--- a/init/main.c
+++ b/init/main.c
@@ -64,6 +64,9 @@
 #include <asm/sections.h>
 #include <asm/cacheflush.h>
 
+#include <asm/pgtable.h>
+#include <asm/tlbflush.h>
+
 #ifdef CONFIG_X86_LOCAL_APIC
 #include <asm/smp.h>
 #endif
@@ -689,9 +692,59 @@ asmlinkage void __init start_kernel(void
 #ifdef CONFIG_SNSC_REDUCE_SPARSEMEM_MEM_CONSUMPTION
 	free_unused_sparsemem_data();
 #endif
+	{/* matrace test */
+		void inval_pgtbl(unsigned int addr);
+		extern unsigned int matrace_v;
+		//extern void _stext, _text, _etext, __data_start, _edata, _end;
+		//unsigned int index;
+		unsigned int  addr;
+
+		addr = matrace_v;
+		inval_pgtbl(addr);
+                // index = pgd_index(addr);
+		// pgd_t  *pgd_k;
+		// pmd_t  *pmd_k;
+		extern pmd_t matrace_saved_pmd;
+
+		// pgd_k = init_mm.pgd + index;
+		// pmd_k = pmd_offset(pgd_k, addr);
+
+		// matrace_saved_pmd = *pmd_k;
+		printk("matrace_v: %x\n", matrace_v);
+		printk("_end: %x\n", _end);
+		printk("matrace_saved_pmd: %x\n\n\n\n", matrace_saved_pmd);
+		//*pmd_k = matrace_saved_pmd & (~0x3);
+		//flush_tlb_all(); /* need to be optimized */
+		//flush_pmd_entry(pmd_k); /* this only flush I/D caches */
+		//v6_flush_kern_cache_all();
+		//matrace_v = 0;
+	}
+
 	rest_init();
 }
+#define __matracer		__attribute__ ((__section__ (".matracer")))
+#define MA_ARRAY_SIZE  (2 * 1024 * 1024)
+char big_array[MA_ARRAY_SIZE]; /* at leat 2M byte */
+unsigned int matrace_v = (unsigned int)&big_array[MA_ARRAY_SIZE / 2];
+pmd_t  matrace_saved_pmd;
+
+/* Invalidate the pagetable entry corresponding to addr */
+void inval_pgtbl(unsigned int addr)
+{
+	unsigned int index;
+	pgd_t  *pgd_k;
+	pmd_t  *pmd_k;
+
+	index = pgd_index(addr);
+	pgd_k = init_mm.pgd + index;
+	pmd_k = pmd_offset(pgd_k, addr);
+	matrace_saved_pmd = *pmd_k;
+	*pmd_k = matrace_saved_pmd & (~0x3);
+	flush_tlb_all(); /* need to be optimized */
+	flush_pmd_entry(pmd_k); /* this only flush I/D caches */
+	v6_flush_kern_cache_all();
 
+}
 
 static int __initdata initcall_debug;
 
Index: b/arch/arm/kernel/process.c
===================================================================
--- a/arch/arm/kernel/process.c
+++ b/arch/arm/kernel/process.c
@@ -151,8 +151,11 @@ void cpu_idle(void)
 
 	/* endless idle loop with no priority at all */
 	while (1) {
+		extern unsigned int  matrace_v;
+		printk("*");
+		*(unsigned int *)matrace_v = 0xdeadbeef;
 		void (*idle)(void) = pm_idle;
-
+		//printk("we returned\n\n");
 #ifdef CONFIG_HOTPLUG_CPU
 		if (cpu_is_offline(smp_processor_id())) {
 			leds_event(led_idle_start);
Index: b/arch/arm/kernel/vmlinux.lds.S
===================================================================
--- a/arch/arm/kernel/vmlinux.lds.S
+++ b/arch/arm/kernel/vmlinux.lds.S
@@ -171,6 +171,8 @@ SECTIONS
 		__bss_start = .;	/* BSS				*/
 		*(.bss)
 		*(COMMON)
+		/*. = ALIGN(0x200000);
+		*(.matracer)*/
 		_end = .;
 	}
 					/* Stabs debugging sections.	*/
Index: b/arch/arm/mm/Makefile
===================================================================
--- a/arch/arm/mm/Makefile
+++ b/arch/arm/mm/Makefile
@@ -2,7 +2,7 @@
 # Makefile for the linux arm-specific parts of the memory manager.
 #
 
-obj-y				:= extable.o fault.o init.o iomap.o
+obj-y				:= extable.o fault.o init.o iomap.o matrace.o
 
 obj-$(CONFIG_MMU)		+= fault-armv.o flush.o ioremap.o mmap.o \
 				   consistent.o pgd.o mmu.o
Index: b/arch/arm/mm/matrace.S
===================================================================
--- /dev/null
+++ b/arch/arm/mm/matrace.S
@@ -0,0 +1,53 @@
+#include <linux/linkage.h>
+#include <asm/assembler.h>
+		.text
+
+@ fp is 0 or stack frame
+#define depth	r2
+#define index	r3
+#define frame	r4
+#define sv_fp	r5
+#define sv_lr	r6
+#define mask	r7
+#define offset	r8
+
+	ENTRY(matrace_magic)
+
+	stmfd	sp!, {r0 - r12, r14}	@ Save an extra register so we have a location...
+
+	ldr  	r1, =trapped_pc
+	ldr 	r1, [r1]	@ get trapped_pc value
+	add	r1, r1, #4	@ r1 = trapped_pc + 4
+
+	adr	r3, pc_val
+	str	r1, [r3]	@ store trapped_pc + 4 to pc_val
+
+	ldr 	r2, =origin_inst
+	ldr	r2, [r2]	@ get original instrution
+
+
+	str	r2, [r1]	@ *(trapped_pc + 4) = origin_inst
+
+	ldr 	r0, =matrace_v
+	ldr	r0, [r0]
+	bl 	inval_pgtbl	@ invalidate pagetable again
+
+	@mov 	r0, r1
+	@add	r1, r0, #128
+	@sub	r0, r0, #128
+	@bl	v6_coherent_kern_range
+	bl	v6_flush_kern_cache_all
+
+	ldmfd	sp!, {r0 - r12, r14}
+	@adr	r0, str_p1
+	@bl	printk
+	ldr 	pc, [pc]
+	nop
+pc_val:
+	.word	0x0
+
+str_p1:	.asciz	"\nwe are in assembler.\n"
+@str_p1:	.asciz	"\nwe are in assembler. traped_pc + 4: %x\n"
+
+var:
+	.word	0xfe000000
